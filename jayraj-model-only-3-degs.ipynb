{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13467802,"sourceType":"datasetVersion","datasetId":8549260}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi\n!pip -q install --upgrade pip\n!pip -q install basicsr timm einops gdown imageio opencv-python albumentations matplotlib torchvision numpy==1.26.4 scipy==1.13.1\n\n# Fresh clone\n!rm -rf Restormer\n!git clone https://github.com/swz30/Restormer.git\n%cd Restormer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport scipy\n\nprint(\"NumPy version:\", np.__version__)\nprint(\"SciPy version:\", scipy.__version__)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ---- TorchVision shim for legacy imports (functional_tensor) ----\nimport sys, types\nimport torch, torchvision\nprint(\"Torch:\", torch.__version__, \"| TorchVision:\", torchvision.__version__)\n\nfrom torchvision.transforms import functional as F\nft_mod = types.ModuleType(\"torchvision.transforms.functional_tensor\")\nfor k, v in F.__dict__.items():\n    setattr(ft_mod, k, v)\nsys.modules[\"torchvision.transforms.functional_tensor\"] = ft_mod\nprint(\"Shim installed: torchvision.transforms.functional_tensor → .functional ✅\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ✅ Run this as a shell cell (notice the ! at the start of each command)\nCKPT_URL=\"https://github.com/swz30/Restormer/releases/download/v1.0/deraining.pth\"\n\n!mkdir -p ./checkpoints\n!rm -f ./checkpoints/pretrained_task.pth\n!curl -L \"$CKPT_URL\" -o ./checkpoints/pretrained_task.pth\n!ls -lh ./checkpoints","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os, torch\nCKPT_PATH = \"./checkpoints/pretrained_task.pth\"\nprint(\"File size (MB):\", os.path.getsize(CKPT_PATH)/1e6)\n# Should be roughly > 50 MB\nassert os.path.getsize(CKPT_PATH) > 10_000_000, \"Checkpoint looks incomplete!\"\n\n# Quick load test\ntry:\n    _ = torch.load(CKPT_PATH, map_location=\"cpu\")\n    print(\"✅ torch.load works fine — checkpoint OK!\")\nexcept Exception as e:\n    print(\"❌ Problem loading checkpoint:\", e)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==== RECOVERY: make sure Restormer is present and importable ====\nimport os, sys, subprocess, shutil, glob, importlib.util\nfrom pathlib import Path\n\nREPO_URL  = \"https://github.com/swz30/Restormer.git\"\nREPO_DIR  = Path(\"/kaggle/working/Restormer\")   # fixed absolute path\n\n# 1) Fresh clone if missing or empty\ndef is_dir_empty(p: Path):\n    return (not p.exists()) or (p.exists() and len(list(p.rglob(\"*\"))) == 0)\n\nif is_dir_empty(REPO_DIR):\n    if REPO_DIR.exists():\n        shutil.rmtree(REPO_DIR, ignore_errors=True)\n    print(\"[i] Cloning Restormer repo...\")\n    subprocess.check_call([\"git\", \"clone\", \"--depth\", \"1\", REPO_URL, str(REPO_DIR)])\nelse:\n    print(\"[i] Restormer repo already present at\", REPO_DIR)\n\n# 2) Put repo on sys.path so 'basicsr' (inside repo) is importable\nif str(REPO_DIR) not in sys.path:\n    sys.path.insert(0, str(REPO_DIR))\nif str(REPO_DIR.parent) not in sys.path:\n    sys.path.insert(0, str(REPO_DIR.parent))\n\n# 3) Try canonical import; if it fails, import by file path\nRestormer = None\ntry:\n    from basicsr.models.archs.restormer_arch import Restormer  # type: ignore\n    print(\"[✓] Imported Restormer from basicsr.models.archs.restormer_arch\")\nexcept Exception as e:\n    print(\"[!] Canonical import failed:\", e)\n    cand = list(REPO_DIR.rglob(\"restormer_arch.py\"))\n    assert cand, \"restormer_arch.py not found under repo\"\n    mod_path = cand[0]\n    spec = importlib.util.spec_from_file_location(\"restormer_local\", str(mod_path))\n    mod = importlib.util.module_from_spec(spec)\n    spec.loader.exec_module(mod)  # type: ignore\n    Restormer = getattr(mod, \"Restormer\")\n    print(f\"[✓] Imported Restormer from file: {mod_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === ONE-CELL SAFE LOADER FOR RESTORMER + CHECKPOINT ===\nimport sys, types, importlib.util, re\nfrom pathlib import Path\nfrom collections import OrderedDict\nimport torch\n\n# ---- Shim for legacy torchvision import used by some basicsr code ----\ntry:\n    from torchvision.transforms import functional as F\n    ft_mod = types.ModuleType(\"torchvision.transforms.functional_tensor\")\n    for k, v in F.__dict__.items():\n        setattr(ft_mod, k, v)\n    sys.modules[\"torchvision.transforms.functional_tensor\"] = ft_mod\n    print(\"Shim ok: torchvision.transforms.functional_tensor -> .functional\")\nexcept Exception as e:\n    print(\"Shim skipped:\", e)\n\n# ---- Robust import of Restormer (canonical or file-path fallback) ----\nrepo_root = \"/kaggle/working/Restormer\"\nif repo_root not in sys.path:\n    sys.path.append(repo_root)\n\nRestormer = None\ntry:\n    from basicsr.models.archs.restormer_arch import Restormer  # type: ignore\n    print(\"Imported Restormer from basicsr.models.archs.restormer_arch\")\nexcept Exception as e:\n    print(\"Canonical import failed:\", e)\n    candidates = list(Path(repo_root).rglob(\"*restormer*.py\"))\n    assert candidates, \"Restormer source not found under repo_root\"\n    p = str(candidates[0])\n    spec = importlib.util.spec_from_file_location(\"restormer_local\", p)\n    mod = importlib.util.module_from_spec(spec)\n    spec.loader.exec_module(mod)  # type: ignore\n    Restormer = getattr(mod, \"Restormer\")\n    print(\"Imported Restormer from file:\", p)\n\n# ---- Load checkpoint and pick the correct inner state dict ----\nckpt_path = \"./checkpoints/pretrained_task.pth\"\nstate = torch.load(ckpt_path, map_location=\"cpu\")\n\nif isinstance(state, dict):\n    if isinstance(state.get(\"params_ema\"), dict):\n        sd = state[\"params_ema\"]; print(\"Using checkpoint['params_ema']\")\n    elif isinstance(state.get(\"params\"), dict):\n        sd = state[\"params\"];     print(\"Using checkpoint['params']\")\n    elif isinstance(state.get(\"state_dict\"), dict):\n        sd = state[\"state_dict\"]; print(\"Using checkpoint['state_dict']\")\n    elif isinstance(state.get(\"model\"), dict):\n        sd = state[\"model\"];      print(\"Using checkpoint['model']\")\n    else:\n        sd = state;               print(\"Using checkpoint as-is (flat dict)\")\nelse:\n    sd = state;                   print(\"Using checkpoint as-is (non-dict)\")\n\n# strip DDP prefix if present\nif any(k.startswith(\"module.\") for k in sd.keys()):\n    sd = OrderedDict((re.sub(r\"^module\\.\", \"\", k), v) for k, v in sd.items())\n    print(\"Stripped 'module.' prefixes\")\n\ndef build_model(layernorm_type: str):\n    return Restormer(\n        inp_channels=3, out_channels=3,\n        dim=48,\n        num_blocks=[4,6,6,8],\n        num_refinement_blocks=4,\n        heads=[1,2,4,8],\n        ffn_expansion_factor=2.66,\n        bias=False,\n        LayerNorm_type=layernorm_type,  # 'WithBias' or 'BiasFree'\n        dual_pixel_task=False\n    )\n\ndef try_load(layernorm_type: str):\n    m = build_model(layernorm_type)\n    missing, unexpected = m.load_state_dict(sd, strict=False)\n    print(f\"[{layernorm_type}] missing: {len(missing)} | unexpected: {len(unexpected)}\")\n    if missing:   print(\"  sample missing:\", missing[:5])\n    if unexpected:print(\"  sample unexpected:\", unexpected[:5])\n    return m, missing, unexpected\n\n# Try BiasFree first, then WithBias\nmodel, missing, unexpected = try_load(\"BiasFree\")\nif missing or unexpected:\n    print(\"Retrying WithBias …\")\n    model, missing, unexpected = try_load(\"WithBias\")\n\nprint(\"\\nFinal -> Loaded with strict=False\")\nprint(\"missing:\", len(missing), \"unexpected:\", len(unexpected))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# freeze everything\nfor p in model.parameters(): p.requires_grad = False\n\n# unfreeze late/refinement + output head (adjust names if needed)\nto_unfreeze = []\nfor n, p in model.named_parameters():\n    if any(k in n.lower() for k in [\"refinement\", \"reconstruct\", \"reconstruction\", \"conv_out\", \"tail\"]):\n        p.requires_grad = True\n        to_unfreeze.append(n)\n\n# fallback: if nothing matched, unfreeze last ~10 params\nif not to_unfreeze:\n    for n,p in list(model.named_parameters())[-10:]:\n        p.requires_grad = True\n        to_unfreeze.append(n)\n\nprint(\"Unfreezing:\", *to_unfreeze[:8], \"...\", sep=\"\\n\")\n\nimport torch\ntrainable = [p for p in model.parameters() if p.requires_grad]\nopt_G = torch.optim.Adam(trainable, lr=1e-5, betas=(0.9,0.999))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.nn as nn, torchvision\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = model.to(device).train()\n\n# perceptual VGG features\nvgg = torchvision.models.vgg19(weights=torchvision.models.VGG19_Weights.IMAGENET1K_V1).features[:16].eval().to(device)\nfor p in vgg.parameters(): p.requires_grad = False\nl1, mse = nn.L1Loss(), nn.MSELoss()\n\n# tiny PatchGAN\nclass PatchD(nn.Module):\n    def __init__(self, in_ch=3, base=64):\n        super().__init__()\n        def blk(ic, oc, norm=True):\n            m=[nn.Conv2d(ic, oc, 4, 2, 1)]\n            if norm: m+=[nn.InstanceNorm2d(oc, affine=True)]\n            m+=[nn.LeakyReLU(0.2, inplace=True)]\n            return nn.Sequential(*m)\n        self.net = nn.Sequential(\n            blk(in_ch, base, norm=False),\n            blk(base, base*2),\n            blk(base*2, base*4),\n            nn.Conv2d(base*4, 1, 3, 1, 1)\n        )\n    def forward(self, x): return self.net(x)\n\ndisc = PatchD().to(device).train()\nopt_D = torch.optim.Adam(disc.parameters(), lr=2e-4, betas=(0.5,0.999))\n\ndef adv_loss(pred, is_real): \n    tgt = torch.ones_like(pred) if is_real else torch.zeros_like(pred)\n    return mse(pred, tgt)\n\nL_ADV, L_PERC, L_ID = 1.0, 0.1, 0.1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==== Multi-degradation dataset & loaders (REPLACES old Cell 8 + 10) ====\nimport os, glob, random, cv2, torch\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nimport albumentations as A\n\n# 1) Point this to the parent folder that contains: clean, fog, rain, lowlight, fog_rain, fog_lowlight, rain_lowlight, extreme\nBASE_DIR = \"/kaggle/input/claude-synthesis\"   # <-- CHANGE THIS to your dataset root\n\nDATA_ROOTS = {\n    \"clean\":        os.path.join(BASE_DIR, \"clean\"),\n    \"fog\":          os.path.join(BASE_DIR, \"fog\"),\n    \"rain\":         os.path.join(BASE_DIR, \"rain\"),\n    \"lowlight\":     os.path.join(BASE_DIR, \"lowlight\"),\n    # \"fog_rain\":     os.path.join(BASE_DIR, \"fog_rain\"),\n    # \"fog_lowlight\": os.path.join(BASE_DIR, \"fog_lowlight\"),\n    # \"rain_lowlight\":os.path.join(BASE_DIR, \"rain_lowlight\"),\n    # \"extreme\":      os.path.join(BASE_DIR, \"extreme\"),\n}\n\nDEG_DOMAINS = [d for d in DATA_ROOTS.keys() if d != \"clean\"]\nCLEAN_DIR   = DATA_ROOTS[\"clean\"]\n\ndef list_images(path):\n    exts = (\"*.jpg\",\"*.jpeg\",\"*.png\",\"*.bmp\")\n    files = []\n    for e in exts:\n        files += glob.glob(os.path.join(path, e))\n        files += glob.glob(os.path.join(path, \"**\", e), recursive=True)\n    if not files:\n        raise FileNotFoundError(f\"No images found in {path}\")\n    return sorted(files)\n\n# 2) Augmentations: keep geometry; gentle photometric jitter only\ntrain_tf = A.Compose([\n    A.LongestMaxSize(max_size=384),\n    A.PadIfNeeded(min_height=384, min_width=384, border_mode=cv2.BORDER_REFLECT_101),\n    A.RandomCrop(256, 256),\n    A.HorizontalFlip(p=0.5),\n    A.RandomBrightnessContrast(0.08, 0.08, p=0.3),  # mild; safe across domains\n])\nval_tf = A.Compose([\n    A.LongestMaxSize(max_size=512),\n    A.PadIfNeeded(min_height=512, min_width=512, border_mode=cv2.BORDER_REFLECT_101),\n])\n\ndef to_tensor(img):\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = np.ascontiguousarray(img).astype(np.float32)/255.0\n    return torch.from_numpy(np.transpose(img,(2,0,1)))\n\nclass UnpairedDataset(Dataset):\n    \"\"\"Returns (degraded_tensor, random_clean_tensor, basename)\"\"\"\n    def __init__(self, deg_files, cln_files, transform=None):\n        self.deg_files, self.cln_files, self.tf = deg_files, cln_files, transform\n    def __len__(self): return len(self.deg_files)\n    def __getitem__(self, idx):\n        dimg = cv2.imread(self.deg_files[idx])\n        cimg = cv2.imread(random.choice(self.cln_files))\n        if self.tf:\n            seed = np.random.randint(0, 999999)\n            random.seed(seed); np.random.seed(seed)\n            dimg = self.tf(image=dimg)['image']\n            random.seed(seed); np.random.seed(seed)\n            cimg = self.tf(image=cimg)['image']\n        return to_tensor(dimg), to_tensor(cimg), os.path.basename(self.deg_files[idx])\n\ndef build_loader_for(domain, batch_size=2, train=True):\n    deg_dir = DATA_ROOTS[domain]\n    deg_files = list_images(deg_dir)\n    cln_files = list_images(CLEAN_DIR)\n    tf = train_tf if train else val_tf\n    ds = UnpairedDataset(deg_files, cln_files, transform=tf)\n    return DataLoader(ds, batch_size=batch_size, shuffle=train, num_workers=2, pin_memory=True, drop_last=train), len(deg_files)\n\n# 3) One train/val loader per domain\ntrain_loaders = {}\nval_loaders   = {}\ncounts = {}\nfor d in DEG_DOMAINS:\n    tl, n = build_loader_for(d, batch_size=2, train=True)\n    vl, _ = build_loader_for(d, batch_size=1, train=False)\n    train_loaders[d] = tl\n    val_loaders[d]   = vl\n    counts[d] = n\n\nprint(\"Domain image counts:\")\nfor d, n in counts.items():\n    print(f\"  {d:12s}: {n}\")\n\nprint(\"\\nTrain loader batches per domain:\")\nfor d, dl in train_loaders.items():\n    print(f\"  {d:12s}: {len(dl)}\")\n\nprint(\"\\nVal samples per domain:\")\nfor d, dl in val_loaders.items():\n    print(f\"  {d:12s}: {len(dl.dataset)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==== Quick per-domain forward check ====\nmodel.eval()\nwith torch.no_grad():\n    for dom, vloader in val_loaders.items():\n        try:\n            d, c, name = next(iter(vloader))\n        except StopIteration:\n            print(f\"[{dom}] empty val loader, skipping\")\n            continue\n        d = d.to(device)\n        o = model(d)\n        print(f\"[{dom}] Shapes: {tuple(d.shape)} -> {tuple(o.shape)}  | sample: {name[0]}\")\nmodel.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==== Stage A: Train one common model across all degradations (REPLACES old Cell 11) ====\nimport os, cv2, numpy as np\nfrom itertools import cycle\nfrom tqdm import tqdm\n\nimport torch\n\n# ---- NEW: metrics (PSNR/SSIM) for saved previews ----\nMETRICS_CSV = \"/kaggle/working/sample_metrics.csv\"\ndef _init_metrics_csv(path=METRICS_CSV):\n    if not os.path.exists(path):\n        with open(path, \"w\") as f:\n            f.write(\"epoch,domain,name,psnr,ssim\\n\")\n\n# skimage helpers (kept tiny; guarded for API differences)\nfrom skimage.metrics import peak_signal_noise_ratio as _psnr\nfrom skimage.metrics import structural_similarity as _ssim\ndef _ssim_safe(ref_rgb_uint8, img_rgb_uint8):\n    try:\n        # new API\n        return _ssim(ref_rgb_uint8, img_rgb_uint8, data_range=255, channel_axis=2)\n    except TypeError:\n        # old API\n        return _ssim(ref_rgb_uint8, img_rgb_uint8, data_range=255, multichannel=True)\n\n# Where previews and checkpoints will be saved\nSAMPLES_ROOT = \"/kaggle/working/samples_mixed\"\nCKPT_ROOT    = \"/kaggle/working/checkpoints_mixed\"   # <-- NEW\nos.makedirs(SAMPLES_ROOT, exist_ok=True)\nos.makedirs(CKPT_ROOT,    exist_ok=True)\n\n# round-robin iterator that yields (domain, batch)\ndef rr_batches(loaders_dict):\n    iters = {k: cycle(v) for k, v in loaders_dict.items()}\n    while True:\n        for k in loaders_dict.keys():\n            yield k, next(iters[k])\n\n# balanced steps: every epoch sees the same number of batches from each domain\nsteps_per_epoch = min(len(dl) for dl in train_loaders.values()) * len(train_loaders)\nprint(\"steps_per_epoch =\", steps_per_epoch)\n\nscalerG = torch.cuda.amp.GradScaler(enabled=(device==\"cuda\"))\nscalerD = torch.cuda.amp.GradScaler(enabled=(device==\"cuda\"))\n\ndef clamp01(x): return torch.clamp(x, 0, 1)\n\n@torch.no_grad()\ndef save_previews_by_domain(epoch):\n    \"\"\"\n    Saves 3 preview triptychs per domain (degraded|output|clean)\n    and RETURNS a list of metric rows (epoch, domain, name, psnr, ssim)\n    computed on the exact samples displayed.\n    \"\"\"\n    model.eval()\n    rows = []\n    for dom, vloader in val_loaders.items():\n        outdir = os.path.join(SAMPLES_ROOT, dom)\n        os.makedirs(outdir, exist_ok=True)\n        cnt = 0\n        for d, c, name in vloader:\n            d, c = d.to(device), c.to(device)\n            o = clamp01(model(d))\n\n            # build triptych preview (unchanged)\n            grid = torch.cat([d[:1], o[:1], c[:1]], dim=3)  # [B,3,H,3W]\n            arr = (grid[0].permute(1,2,0).cpu().numpy()*255).astype(np.uint8)\n            cv2.imwrite(\n                os.path.join(outdir, f\"ep{epoch:03d}_{dom}_{name[0]}\"),\n                cv2.cvtColor(arr, cv2.COLOR_RGB2BGR)\n            )\n\n            # ---- NEW: compute PSNR/SSIM for the shown sample (output vs clean) ----\n            # use the same first item we visualized\n            out_img = (o[0].permute(1,2,0).cpu().numpy()*255).astype(np.uint8)   # RGB uint8\n            gt_img  = (c[0].permute(1,2,0).cpu().numpy()*255).astype(np.uint8)   # RGB uint8\n            psnr = float(_psnr(gt_img, out_img, data_range=255))\n            ssim = float(_ssim_safe(gt_img, out_img))\n            rows.append((epoch, dom, name[0], psnr, ssim))\n\n            cnt += 1\n            if cnt >= 3:  # a few previews per domain\n                break\n    model.train()\n    return rows\n\n# Init the tiny CSV once\n_init_metrics_csv(METRICS_CSV)\n\nEPOCHS = 10  # 5–7 is a good range for base robustness\nrr = rr_batches(train_loaders)\n\nfor ep in range(1, EPOCHS+1):\n    pbar = tqdm(range(steps_per_epoch), desc=f\"Epoch {ep}/{EPOCHS}\")\n    model.train(); disc.train()\n    for _ in pbar:\n        domain, batch = next(rr)\n        degraded, clean, _ = batch\n        degraded, clean = degraded.to(device, non_blocking=True), clean.to(device, non_blocking=True)\n\n        # --- G step ---\n        opt_G.zero_grad(set_to_none=True)\n        with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n            fake = model(degraded)\n            loss_g_adv  = adv_loss(disc(fake), True) * L_ADV\n            loss_g_perc = l1(vgg(fake), vgg(clean)) * L_PERC\n            loss_g_id   = l1(model(clean), clean) * L_ID\n            loss_g = loss_g_adv + loss_g_perc + loss_g_id\n        scalerG.scale(loss_g).backward()\n        scalerG.step(opt_G); scalerG.update()\n\n        # --- D step ---\n        opt_D.zero_grad(set_to_none=True)\n        with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n            r = disc(clean); f = disc(fake.detach())\n            loss_d = 0.5*(adv_loss(r, True) + adv_loss(f, False))\n        scalerD.scale(loss_d).backward()\n        scalerD.step(opt_D); scalerD.update()\n\n        pbar.set_postfix(G=float(loss_g.item()), D=float(loss_d.item()), dom=domain)\n\n    # ---- NEW: save epoch-specific checkpoint ----\n    ep_ckpt = os.path.join(CKPT_ROOT, f\"restormer_mixed_ep{ep:03d}.pth\")\n    torch.save(model.state_dict(), ep_ckpt)\n\n    # (optional: keep your original single-name checkpoint too)\n    torch.save(model.state_dict(), \"./restormer_mixed_base.pth\")\n\n    # ---- previews + sample metrics (PSNR/SSIM for those exact images) ----\n    sample_rows = save_previews_by_domain(ep)\n    if sample_rows:\n        with open(METRICS_CSV, \"a\") as f:\n            for row in sample_rows:\n                f.write(\",\".join(map(str, row)) + \"\\n\")\n\nprint(\"✅ Stage A done.\")\nprint(f\"Per-epoch checkpoints: {CKPT_ROOT}/restormer_mixed_epXXX.pth\")\nprint(f\"Also wrote: ./restormer_mixed_base.pth (last epoch)\")\nprint(f\"Previews:    {SAMPLES_ROOT}/<domain>/\")\nprint(f\"Sample metrics CSV: {METRICS_CSV} (columns: epoch,domain,name,psnr,ssim)\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # ==== Stage A: Train one common model across all degradations (metrics + per-epoch ckpts) ====\n# import os, cv2, time, json, numpy as np\n# from itertools import cycle\n# from collections import Counter\n# from contextlib import suppress\n# from tqdm import tqdm\n\n# import torch\n# import torch.nn.functional as F\n\n# # ---------- Paths ----------\n# SAMPLES_ROOT = \"/kaggle/working/samples_mixed\"\n# CKPT_ROOT    = \"/kaggle/working/checkpoints_mixed\"\n# LOG_ROOT     = \"/kaggle/working/logs_mixed\"\n# os.makedirs(SAMPLES_ROOT, exist_ok=True)\n# os.makedirs(CKPT_ROOT,    exist_ok=True)\n# os.makedirs(LOG_ROOT,     exist_ok=True)\n\n# METRICS_CSV   = os.path.join(LOG_ROOT, \"metrics_summary.csv\")\n# TRAIN_CSV     = os.path.join(LOG_ROOT, \"train_trace_epoch.csv\")        # A1\n# DOMCOUNT_CSV  = os.path.join(LOG_ROOT, \"domain_steps.csv\")             # A2\n# BEST_CSV      = os.path.join(LOG_ROOT, \"best_epochs_per_domain.csv\")   # A3\n\n# # ---------- Metrics helpers ----------\n# _have_brisque = False\n# _have_niqe = False\n# try:\n#     from skimage.metrics import peak_signal_noise_ratio as _psnr\n#     from skimage.metrics import structural_similarity as _ssim\n#     try:\n#         from skimage.metrics import niqe as _niqe\n#         _have_niqe = True\n#     except Exception:\n#         _have_niqe = False\n#     try:\n#         from skimage.metrics import brisque as _brisque\n#         _have_brisque = True\n#     except Exception:\n#         _have_brisque = False\n# except Exception as e:\n#     raise RuntimeError(\n#         \"scikit-image not available; run `pip install -q scikit-image` in a Kaggle cell.\"\n#     ) from e\n\n# def _ssim_safe(img, ref):\n#     \"\"\"Handle skimage API differences (channel_axis vs multichannel).\"\"\"\n#     try:\n#         return _ssim(ref, img, data_range=255, channel_axis=2)\n#     except TypeError:\n#         return _ssim(ref, img, data_range=255, multichannel=True)\n\n# def clamp01(x): \n#     return torch.clamp(x, 0, 1)\n\n# def rr_batches(loaders_dict):\n#     iters = {k: cycle(v) for k, v in loaders_dict.items()}\n#     while True:\n#         for k in loaders_dict.keys():\n#             yield k, next(iters[k])\n\n# def init_metrics_csv(path):\n#     if not os.path.exists(path):\n#         cols = [\"epoch\",\"domain\",\"psnr\",\"ssim\"]\n#         if _have_niqe: cols.append(\"niqe\")\n#         if _have_brisque: cols.append(\"brisque\")\n#         cols += [\"mean_G_loss\",\"mean_D_loss\",\"mean_adv\",\"mean_perc\",\"mean_id\"]\n#         with open(path, \"w\", encoding=\"utf-8\") as f:\n#             f.write(\",\".join(cols) + \"\\n\")\n\n# def init_train_csv(path):  # A1 header\n#     if not os.path.exists(path):\n#         with open(path, \"w\", encoding=\"utf-8\") as f:\n#             f.write(\"epoch,steps,batch_size,imgs_seen,sec_per_epoch,imgs_per_sec,lr_G,lr_D,mean_G,mean_D,mean_adv,mean_perc,mean_id\\n\")\n\n# def init_domcount_csv(path):  # A2 header\n#     if not os.path.exists(path):\n#         with open(path, \"w\", encoding=\"utf-8\") as f:\n#             f.write(\"epoch,domain,steps\\n\")\n\n# def init_best_csv(path):  # A3 header\n#     if not os.path.exists(path):\n#         with open(path, \"w\", encoding=\"utf-8\") as f:\n#             f.write(\"domain,best_psnr_epoch,best_psnr,best_ssim_epoch,best_ssim,ckpt_at_best_psnr,ckpt_at_best_ssim\\n\")\n\n# def write_metrics_row(path, epoch, domain, metrics, loss_means):\n#     cols = [\n#         str(epoch),\n#         domain,\n#         f\"{metrics.get('psnr', np.nan)}\",\n#         f\"{metrics.get('ssim', np.nan)}\",\n#     ]\n#     if _have_niqe:    cols.append(f\"{metrics.get('niqe', np.nan)}\")\n#     if _have_brisque: cols.append(f\"{metrics.get('brisque', np.nan)}\")\n#     cols += [\n#         f\"{loss_means['G']}\",\n#         f\"{loss_means['D']}\",\n#         f\"{loss_means['adv']}\",\n#         f\"{loss_means['perc']}\",\n#         f\"{loss_means['id']}\",\n#     ]\n#     with open(path, \"a\", encoding=\"utf-8\") as f:\n#         f.write(\",\".join(cols) + \"\\n\")\n\n# def compute_metrics_batch(fake_t, clean_t):\n#     \"\"\"\n#     fake_t, clean_t: tensors in [0,1], shape [B,3,H,W]\n#     Returns dict of mean metrics over the batch.\n#     \"\"\"\n#     fake = (fake_t.detach().clamp(0,1).cpu().permute(0,2,3,1).numpy() * 255).astype(np.uint8)\n#     gt   = (clean_t.detach().clamp(0,1).cpu().permute(0,2,3,1).numpy() * 255).astype(np.uint8)\n\n#     psnr_vals, ssim_vals, niqe_vals, brisque_vals = [], [], [], []\n#     for f, r in zip(fake, gt):\n#         try: psnr_vals.append(_psnr(r, f, data_range=255))\n#         except: pass\n#         try: ssim_vals.append(_ssim_safe(f, r))\n#         except: pass\n#         if _have_niqe:\n#             try:\n#                 g = cv2.cvtColor(f, cv2.COLOR_RGB2GRAY).astype(np.float64) / 255.0\n#                 niqe_vals.append(_niqe(g))\n#             except: pass\n#         if _have_brisque:\n#             try:\n#                 g = cv2.cvtColor(f, cv2.COLOR_RGB2GRAY).astype(np.float64) / 255.0\n#                 brisque_vals.append(_brisque(g))\n#             except: pass\n\n#     out = {\n#         \"psnr\": float(np.mean(psnr_vals)) if psnr_vals else np.nan,\n#         \"ssim\": float(np.mean(ssim_vals)) if ssim_vals else np.nan,\n#     }\n#     if _have_niqe:    out[\"niqe\"] = float(np.mean(niqe_vals)) if niqe_vals else np.nan\n#     if _have_brisque: out[\"brisque\"] = float(np.mean(brisque_vals)) if brisque_vals else np.nan\n#     return out\n\n# @torch.no_grad()\n# def save_previews_by_domain(epoch):\n#     model.eval()\n#     for dom, vloader in val_loaders.items():\n#         outdir = os.path.join(SAMPLES_ROOT, dom)\n#         os.makedirs(outdir, exist_ok=True)\n#         cnt = 0\n#         for d, c, name in vloader:\n#             d, c = d.to(device), c.to(device)\n#             o = clamp01(model(d))\n#             grid = torch.cat([d[:1], o[:1], c[:1]], dim=3)  # [B,3,H,3W]\n#             arr = (grid[0].permute(1,2,0).cpu().numpy()*255).astype(np.uint8)\n#             cv2.imwrite(\n#                 os.path.join(outdir, f\"ep{epoch:03d}_{dom}_{name[0]}.jpg\"),\n#                 cv2.cvtColor(arr, cv2.COLOR_RGB2BGR)\n#             )\n#             cnt += 1\n#             if cnt >= 3:  # a few previews per domain\n#                 break\n#     model.train()\n\n# @torch.no_grad()\n# def evaluate_domains(epoch):\n#     \"\"\"\n#     Evaluate model on validation sets per domain.\n#     Returns { domain: {psnr, ssim, (niqe), (brisque)} } averaged over the loader.\n#     \"\"\"\n#     model.eval()\n#     results = {}\n#     for dom, vloader in val_loaders.items():\n#         vals = {\"psnr\": [], \"ssim\": []}\n#         if _have_niqe: vals[\"niqe\"] = []\n#         if _have_brisque: vals[\"brisque\"] = []\n\n#         for d, c, _ in vloader:\n#             d, c = d.to(device), c.to(device)\n#             o = clamp01(model(d))\n#             m = compute_metrics_batch(o, c)\n#             for k, v in m.items():\n#                 vals[k].append(v)\n\n#         results[dom] = {k: (float(np.nanmean(v)) if len(v) else np.nan) for k, v in vals.items()}\n#     model.train()\n#     return results\n\n# # ---------- Train ----------\n# steps_per_epoch = min(len(dl) for dl in train_loaders.values()) * len(train_loaders)\n# print(\"steps_per_epoch =\", steps_per_epoch)\n\n# scalerG = torch.cuda.amp.GradScaler(enabled=(device==\"cuda\"))\n# scalerD = torch.cuda.amp.GradScaler(enabled=(device==\"cuda\"))\n\n# # init logs\n# init_metrics_csv(METRICS_CSV)\n# init_train_csv(TRAIN_CSV)       # A1\n# init_domcount_csv(DOMCOUNT_CSV) # A2\n# init_best_csv(BEST_CSV)         # A3\n\n# # in-memory best tracker (A3)\n# _best = {}  # domain -> {psnr, psnr_epoch, ssim, ssim_epoch, ckpt_psnr, ckpt_ssim}\n\n# EPOCHS = 25  # keep as you set\n# rr = rr_batches(train_loaders)\n\n# for ep in range(1, EPOCHS+1):\n#     pbar = tqdm(range(steps_per_epoch), desc=f\"Epoch {ep}/{EPOCHS}\")\n#     model.train(); disc.train()\n\n#     # A1/A2 bookkeeping\n#     epoch_start = time.perf_counter()\n#     dom_counter = Counter()\n#     batch_size_seen = None\n\n#     # running sums for loss means\n#     sum_G = sum_D = 0.0\n#     sum_adv = sum_perc = sum_id = 0.0\n#     n_steps = 0\n\n#     for _ in pbar:\n#         domain, batch = next(rr)\n#         degraded, clean, _ = batch\n#         degraded = degraded.to(device, non_blocking=True)\n#         clean    = clean.to(device, non_blocking=True)\n\n#         # record domain step (A2) + batch size (A1)\n#         dom_counter[domain] += 1\n#         if batch_size_seen is None:\n#             batch_size_seen = degraded.size(0)\n\n#         # --- G step ---\n#         opt_G.zero_grad(set_to_none=True)\n#         with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n#             fake = model(degraded)\n#             loss_g_adv  = adv_loss(disc(fake), True) * L_ADV\n#             loss_g_perc = l1(vgg(fake), vgg(clean)) * L_PERC\n#             loss_g_id   = l1(model(clean), clean) * L_ID\n#             loss_g = loss_g_adv + loss_g_perc + loss_g_id\n#         scalerG.scale(loss_g).backward()\n#         scalerG.step(opt_G); scalerG.update()\n\n#         # --- D step ---\n#         opt_D.zero_grad(set_to_none=True)\n#         with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n#             r = disc(clean); f = disc(fake.detach())\n#             loss_d = 0.5*(adv_loss(r, True) + adv_loss(f, False))\n#         scalerD.scale(loss_d).backward()\n#         scalerD.step(opt_D); scalerD.update()\n\n#         # running logs\n#         sum_G   += float(loss_g.item())\n#         sum_D   += float(loss_d.item())\n#         sum_adv += float(loss_g_adv.item())\n#         sum_perc+= float(loss_g_perc.item())\n#         sum_id  += float(loss_g_id.item())\n#         n_steps += 1\n\n#         pbar.set_postfix(G=float(loss_g.item()), D=float(loss_d.item()), dom=domain)\n\n#     # mean losses for the epoch\n#     denom = max(1, n_steps)\n#     loss_means = {\n#         \"G\":   round(sum_G/denom, 6),\n#         \"D\":   round(sum_D/denom, 6),\n#         \"adv\": round(sum_adv/denom, 6),\n#         \"perc\":round(sum_perc/denom, 6),\n#         \"id\":  round(sum_id/denom, 6),\n#     }\n\n#     # ---- save checkpoint (separate per epoch) ----\n#     ckpt_path = os.path.join(CKPT_ROOT, f\"restormer_mixed_ep{ep:03d}.pth\")\n#     torch.save(model.state_dict(), ckpt_path)\n#     # also keep a latest pointer\n#     torch.save(model.state_dict(), os.path.join(CKPT_ROOT, \"restormer_mixed_latest.pth\"))\n\n#     # ---- previews + metrics per domain ----\n#     save_previews_by_domain(ep)\n#     dom_metrics = evaluate_domains(ep)\n#     for dom, metrics in dom_metrics.items():\n#         write_metrics_row(METRICS_CSV, ep, dom, metrics, loss_means)\n\n#     # ---- A1: epoch timing, throughput, learning rates ----\n#     epoch_time = time.perf_counter() - epoch_start\n#     imgs_seen  = int(n_steps * (batch_size_seen if batch_size_seen is not None else 0))\n#     with suppress(Exception):\n#         lr_G = opt_G.param_groups[0]['lr']\n#     with suppress(Exception):\n#         lr_D = opt_D.param_groups[0]['lr']\n#     lr_G = lr_G if 'lr_G' in locals() else float('nan')\n#     lr_D = lr_D if 'lr_D' in locals() else float('nan')\n#     with open(TRAIN_CSV, \"a\", encoding=\"utf-8\") as f:\n#         f.write(\",\".join(map(str, [\n#             ep, n_steps, (batch_size_seen or 0), imgs_seen,\n#             round(epoch_time, 4),\n#             round(imgs_seen/max(1e-8, epoch_time), 3),\n#             lr_G, lr_D,\n#             loss_means[\"G\"], loss_means[\"D\"], loss_means[\"adv\"], loss_means[\"perc\"], loss_means[\"id\"]\n#         ])) + \"\\n\")\n\n#     # ---- A2: write domain step counts ----\n#     with open(DOMCOUNT_CSV, \"a\", encoding=\"utf-8\") as f:\n#         for dname, steps in sorted(dom_counter.items()):\n#             f.write(f\"{ep},{dname},{steps}\\n\")\n\n#     # ---- A3: update best epochs per domain (by PSNR & SSIM) ----\n#     for dom, m in dom_metrics.items():\n#         cur = _best.get(dom, {\"psnr\": -1, \"ssim\": -1})\n#         # PSNR\n#         if m.get(\"psnr\", -1) > cur.get(\"psnr\", -1):\n#             cur[\"psnr\"] = m[\"psnr\"]\n#             cur[\"psnr_epoch\"] = ep\n#             cur[\"ckpt_psnr\"] = ckpt_path\n#         # SSIM\n#         if m.get(\"ssim\", -1) > cur.get(\"ssim\", -1):\n#             cur[\"ssim\"] = m[\"ssim\"]\n#             cur[\"ssim_epoch\"] = ep\n#             cur[\"ckpt_ssim\"] = ckpt_path\n#         _best[dom] = cur\n\n#     # flush best table after each epoch\n#     with open(BEST_CSV, \"w\", encoding=\"utf-8\") as f:\n#         f.write(\"domain,best_psnr_epoch,best_psnr,best_ssim_epoch,best_ssim,ckpt_at_best_psnr,ckpt_at_best_ssim\\n\")\n#         for dom, cur in sorted(_best.items()):\n#             f.write(\",\".join(map(str, [\n#                 dom,\n#                 cur.get(\"psnr_epoch\",\"\"),\n#                 cur.get(\"psnr\",\"\"),\n#                 cur.get(\"ssim_epoch\",\"\"),\n#                 cur.get(\"ssim\",\"\"),\n#                 cur.get(\"ckpt_psnr\",\"\"),\n#                 cur.get(\"ckpt_ssim\",\"\"),\n#             ])) + \"\\n\")\n\n# print(\"✅ Stage A done.\")\n# print(f\"Checkpoints: {CKPT_ROOT}/restormer_mixed_epXXX.pth (+ restormer_mixed_latest.pth)\")\n# print(f\"Previews:    {SAMPLES_ROOT}/<domain>/\")\n# print(f\"Metrics CSV: {METRICS_CSV}\")\n# print(f\"A1: Train trace: {TRAIN_CSV}\")\n# print(f\"A2: Domain steps: {DOMCOUNT_CSV}\")\n# print(f\"A3: Best epochs:  {BEST_CSV}\")\n","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # ==== Stage A: Train one common model across all degradations (metrics + per-epoch ckpts) ====\n# import os, cv2, time, json, numpy as np\n# from itertools import cycle\n# from tqdm import tqdm\n\n# import torch\n# import torch.nn.functional as F\n\n# # ---------- Paths ----------\n# SAMPLES_ROOT = \"/kaggle/working/samples_mixed\"\n# CKPT_ROOT    = \"/kaggle/working/checkpoints_mixed\"\n# LOG_ROOT     = \"/kaggle/working/logs_mixed\"\n# os.makedirs(SAMPLES_ROOT, exist_ok=True)\n# os.makedirs(CKPT_ROOT,    exist_ok=True)\n# os.makedirs(LOG_ROOT,     exist_ok=True)\n\n# METRICS_CSV = os.path.join(LOG_ROOT, \"metrics_summary.csv\")\n\n# # ---------- Metrics helpers ----------\n# _have_brisque = False\n# _have_niqe = False\n# try:\n#     from skimage.metrics import peak_signal_noise_ratio as _psnr\n#     from skimage.metrics import structural_similarity as _ssim\n#     try:\n#         from skimage.metrics import niqe as _niqe\n#         _have_niqe = True\n#     except Exception:\n#         _have_niqe = False\n#     try:\n#         from skimage.metrics import brisque as _brisque\n#         _have_brisque = True\n#     except Exception:\n#         _have_brisque = False\n# except Exception as e:\n#     raise RuntimeError(\n#         \"scikit-image not available; run `pip install -q scikit-image` in a Kaggle cell.\"\n#     ) from e\n\n# def _ssim_safe(img, ref):\n#     \"\"\"Handle skimage API differences (channel_axis vs multichannel).\"\"\"\n#     try:\n#         return _ssim(ref, img, data_range=255, channel_axis=2)\n#     except TypeError:\n#         return _ssim(ref, img, data_range=255, multichannel=True)\n\n# def clamp01(x): \n#     return torch.clamp(x, 0, 1)\n\n# def rr_batches(loaders_dict):\n#     iters = {k: cycle(v) for k, v in loaders_dict.items()}\n#     while True:\n#         for k in loaders_dict.keys():\n#             yield k, next(iters[k])\n\n# def init_metrics_csv(path):\n#     if not os.path.exists(path):\n#         cols = [\"epoch\",\"domain\",\"psnr\",\"ssim\"]\n#         if _have_niqe: cols.append(\"niqe\")\n#         if _have_brisque: cols.append(\"brisque\")\n#         cols += [\"mean_G_loss\",\"mean_D_loss\",\"mean_adv\",\"mean_perc\",\"mean_id\"]\n#         with open(path, \"w\", encoding=\"utf-8\") as f:\n#             f.write(\",\".join(cols) + \"\\n\")\n\n# def write_metrics_row(path, epoch, domain, metrics, loss_means):\n#     cols = [\n#         str(epoch),\n#         domain,\n#         f\"{metrics.get('psnr', np.nan)}\",\n#         f\"{metrics.get('ssim', np.nan)}\",\n#     ]\n#     if _have_niqe:    cols.append(f\"{metrics.get('niqe', np.nan)}\")\n#     if _have_brisque: cols.append(f\"{metrics.get('brisque', np.nan)}\")\n#     cols += [\n#         f\"{loss_means['G']}\",\n#         f\"{loss_means['D']}\",\n#         f\"{loss_means['adv']}\",\n#         f\"{loss_means['perc']}\",\n#         f\"{loss_means['id']}\",\n#     ]\n#     with open(path, \"a\", encoding=\"utf-8\") as f:\n#         f.write(\",\".join(cols) + \"\\n\")\n\n# def compute_metrics_batch(fake_t, clean_t):\n#     \"\"\"\n#     fake_t, clean_t: tensors in [0,1], shape [B,3,H,W]\n#     Returns dict of mean metrics over the batch.\n#     \"\"\"\n#     fake = (fake_t.detach().clamp(0,1).cpu().permute(0,2,3,1).numpy() * 255).astype(np.uint8)\n#     gt   = (clean_t.detach().clamp(0,1).cpu().permute(0,2,3,1).numpy() * 255).astype(np.uint8)\n\n#     psnr_vals, ssim_vals, niqe_vals, brisque_vals = [], [], [], []\n#     for f, r in zip(fake, gt):\n#         try: psnr_vals.append(_psnr(r, f, data_range=255))\n#         except: pass\n#         try: ssim_vals.append(_ssim_safe(f, r))\n#         except: pass\n#         if _have_niqe:\n#             try:\n#                 g = cv2.cvtColor(f, cv2.COLOR_RGB2GRAY).astype(np.float64) / 255.0\n#                 niqe_vals.append(_niqe(g))\n#             except: pass\n#         if _have_brisque:\n#             try:\n#                 g = cv2.cvtColor(f, cv2.COLOR_RGB2GRAY).astype(np.float64) / 255.0\n#                 brisque_vals.append(_brisque(g))\n#             except: pass\n\n#     out = {\n#         \"psnr\": float(np.mean(psnr_vals)) if psnr_vals else np.nan,\n#         \"ssim\": float(np.mean(ssim_vals)) if ssim_vals else np.nan,\n#     }\n#     if _have_niqe:    out[\"niqe\"] = float(np.mean(niqe_vals)) if niqe_vals else np.nan\n#     if _have_brisque: out[\"brisque\"] = float(np.mean(brisque_vals)) if brisque_vals else np.nan\n#     return out\n\n# @torch.no_grad()\n# def save_previews_by_domain(epoch):\n#     model.eval()\n#     for dom, vloader in val_loaders.items():\n#         outdir = os.path.join(SAMPLES_ROOT, dom)\n#         os.makedirs(outdir, exist_ok=True)\n#         cnt = 0\n#         for d, c, name in vloader:\n#             d, c = d.to(device), c.to(device)\n#             o = clamp01(model(d))\n#             grid = torch.cat([d[:1], o[:1], c[:1]], dim=3)  # [B,3,H,3W]\n#             arr = (grid[0].permute(1,2,0).cpu().numpy()*255).astype(np.uint8)\n#             cv2.imwrite(\n#                 os.path.join(outdir, f\"ep{epoch:03d}_{dom}_{name[0]}.jpg\"),\n#                 cv2.cvtColor(arr, cv2.COLOR_RGB2BGR)\n#             )\n#             cnt += 1\n#             if cnt >= 3:  # a few previews per domain\n#                 break\n#     model.train()\n\n# @torch.no_grad()\n# def evaluate_domains(epoch):\n#     \"\"\"\n#     Evaluate model on validation sets per domain.\n#     Returns { domain: {psnr, ssim, (niqe), (brisque)} } averaged over the loader.\n#     \"\"\"\n#     model.eval()\n#     results = {}\n#     for dom, vloader in val_loaders.items():\n#         vals = {\"psnr\": [], \"ssim\": []}\n#         if _have_niqe: vals[\"niqe\"] = []\n#         if _have_brisque: vals[\"brisque\"] = []\n\n#         for d, c, _ in vloader:\n#             d, c = d.to(device), c.to(device)\n#             o = clamp01(model(d))\n#             m = compute_metrics_batch(o, c)\n#             for k, v in m.items():\n#                 vals[k].append(v)\n\n#         results[dom] = {k: (float(np.nanmean(v)) if len(v) else np.nan) for k, v in vals.items()}\n#     model.train()\n#     return results\n\n# # ---------- Train ----------\n# steps_per_epoch = min(len(dl) for dl in train_loaders.values()) * len(train_loaders)\n# print(\"steps_per_epoch =\", steps_per_epoch)\n\n# scalerG = torch.cuda.amp.GradScaler(enabled=(device==\"cuda\"))\n# scalerD = torch.cuda.amp.GradScaler(enabled=(device==\"cuda\"))\n\n# init_metrics_csv(METRICS_CSV)\n\n# EPOCHS = 25  # keep as you set\n# rr = rr_batches(train_loaders)\n\n# for ep in range(1, EPOCHS+1):\n#     pbar = tqdm(range(steps_per_epoch), desc=f\"Epoch {ep}/{EPOCHS}\")\n#     model.train(); disc.train()\n\n#     # running sums for loss means\n#     sum_G = sum_D = 0.0\n#     sum_adv = sum_perc = sum_id = 0.0\n#     n_steps = 0\n\n#     for _ in pbar:\n#         domain, batch = next(rr)\n#         degraded, clean, _ = batch\n#         degraded = degraded.to(device, non_blocking=True)\n#         clean    = clean.to(device, non_blocking=True)\n\n#         # --- G step ---\n#         opt_G.zero_grad(set_to_none=True)\n#         with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n#             fake = model(degraded)\n#             loss_g_adv  = adv_loss(disc(fake), True) * L_ADV\n#             loss_g_perc = l1(vgg(fake), vgg(clean)) * L_PERC\n#             loss_g_id   = l1(model(clean), clean) * L_ID\n#             loss_g = loss_g_adv + loss_g_perc + loss_g_id\n#         scalerG.scale(loss_g).backward()\n#         scalerG.step(opt_G); scalerG.update()\n\n#         # --- D step ---\n#         opt_D.zero_grad(set_to_none=True)\n#         with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n#             r = disc(clean); f = disc(fake.detach())\n#             loss_d = 0.5*(adv_loss(r, True) + adv_loss(f, False))\n#         scalerD.scale(loss_d).backward()\n#         scalerD.step(opt_D); scalerD.update()\n\n#         # running logs\n#         sum_G   += float(loss_g.item())\n#         sum_D   += float(loss_d.item())\n#         sum_adv += float(loss_g_adv.item())\n#         sum_perc+= float(loss_g_perc.item())\n#         sum_id  += float(loss_g_id.item())\n#         n_steps += 1\n\n#         pbar.set_postfix(G=float(loss_g.item()), D=float(loss_d.item()), dom=domain)\n\n#     # mean losses for the epoch\n#     denom = max(1, n_steps)\n#     loss_means = {\n#         \"G\":   round(sum_G/denom, 6),\n#         \"D\":   round(sum_D/denom, 6),\n#         \"adv\": round(sum_adv/denom, 6),\n#         \"perc\":round(sum_perc/denom, 6),\n#         \"id\":  round(sum_id/denom, 6),\n#     }\n\n#     # ---- save checkpoint (separate per epoch) ----\n#     ckpt_path = os.path.join(CKPT_ROOT, f\"restormer_mixed_ep{ep:03d}.pth\")\n#     torch.save(model.state_dict(), ckpt_path)\n#     # also keep a latest pointer\n#     torch.save(model.state_dict(), os.path.join(CKPT_ROOT, \"restormer_mixed_latest.pth\"))\n\n#     # ---- previews + metrics per domain ----\n#     save_previews_by_domain(ep)\n#     dom_metrics = evaluate_domains(ep)\n#     for dom, metrics in dom_metrics.items():\n#         write_metrics_row(METRICS_CSV, ep, dom, metrics, loss_means)\n\n# print(\"✅ Stage A done.\")\n# print(f\"Checkpoints: {CKPT_ROOT}/restormer_mixed_epXXX.pth (+ restormer_mixed_latest.pth)\")\n# print(f\"Previews:    {SAMPLES_ROOT}/<domain>/\")\n# print(f\"Metrics CSV: {METRICS_CSV}\")\n","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==== Zip all generated outputs ====\nimport os, shutil\nfrom datetime import datetime\n\nOUTPUT_ROOT = \"/kaggle/working\"\nZIP_NAME = f\"restormer_outputs_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip\"\nZIP_PATH = os.path.join(OUTPUT_ROOT, ZIP_NAME)\n\n# Include these paths if they exist\nINCLUDE = [\n    \"samples_mixed\",            # previews\n    \"checkpoints_mixed\",        # per-epoch .pth\n    \"sample_metrics.csv\",       # PSNR/SSIM for preview samples\n    \"restormer_mixed_base.pth\", # last-epoch convenience checkpoint\n]\n\npaths = [os.path.join(OUTPUT_ROOT, p) for p in INCLUDE if os.path.exists(os.path.join(OUTPUT_ROOT, p))]\n\nif not paths:\n    print(\"⚠️ No generated files found to zip.\")\nelse:\n    print(\"Adding to archive:\")\n    for p in paths:\n        print(\"  -\", p)\n    # Easiest: zip the entire /kaggle/working (small project) so relative paths stay intact\n    shutil.make_archive(ZIP_PATH[:-4], 'zip', OUTPUT_ROOT)\n    print(f\"\\n✅ Zipped to: {ZIP_PATH}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T03:31:16.023017Z","iopub.execute_input":"2025-11-02T03:31:16.023612Z","iopub.status.idle":"2025-11-02T03:31:18.42864Z","shell.execute_reply.started":"2025-11-02T03:31:16.023587Z","shell.execute_reply":"2025-11-02T03:31:18.427565Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==== Graphs from sample_metrics.csv ====\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nMETRICS_CSV = \"/kaggle/working/sample_metrics.csv\"\nassert os.path.exists(METRICS_CSV), \"sample_metrics.csv not found. Run training cell first.\"\n\ndf = pd.read_csv(METRICS_CSV)  # columns: epoch,domain,name,psnr,ssim\ndf[\"epoch\"] = df[\"epoch\"].astype(int)\n\n# Aggregate: mean per (epoch, domain)\nagg = df.groupby([\"epoch\",\"domain\"], as_index=False).agg(\n    psnr_mean=(\"psnr\",\"mean\"),\n    psnr_std =(\"psnr\",\"std\"),\n    ssim_mean=(\"ssim\",\"mean\"),\n    ssim_std =(\"ssim\",\"std\"),\n    n=(\"name\",\"count\")\n)\n\n# 1) PSNR vs Epoch — per domain\nfor dom in sorted(agg[\"domain\"].unique()):\n    sub = agg[agg[\"domain\"] == dom]\n    plt.figure()\n    plt.plot(sub[\"epoch\"], sub[\"psnr_mean\"], marker=\"o\")\n    plt.title(f\"PSNR vs Epoch — {dom}\")\n    plt.xlabel(\"Epoch\"); plt.ylabel(\"PSNR (dB)\")\n    plt.grid(True); plt.show()\n\n# 2) SSIM vs Epoch — per domain\nfor dom in sorted(agg[\"domain\"].unique()):\n    sub = agg[agg[\"domain\"] == dom]\n    plt.figure()\n    plt.plot(sub[\"epoch\"], sub[\"ssim_mean\"], marker=\"o\")\n    plt.title(f\"SSIM vs Epoch — {dom}\")\n    plt.xlabel(\"Epoch\"); plt.ylabel(\"SSIM\")\n    plt.grid(True); plt.show()\n\n# 3) Last-epoch bar charts (mean ± std) per domain\nlast_ep = agg[\"epoch\"].max()\nlast = agg[agg[\"epoch\"] == last_ep].copy().sort_values(\"domain\")\n\nplt.figure()\nplt.bar(last[\"domain\"], last[\"psnr_mean\"], yerr=last[\"psnr_std\"], capsize=3)\nplt.title(f\"PSNR by Domain — Last Epoch {last_ep}\")\nplt.xlabel(\"Domain\"); plt.ylabel(\"PSNR (dB)\")\nplt.xticks(rotation=20); plt.grid(True, axis=\"y\"); plt.show()\n\nplt.figure()\nplt.bar(last[\"domain\"], last[\"ssim_mean\"], yerr=last[\"ssim_std\"], capsize=3)\nplt.title(f\"SSIM by Domain — Last Epoch {last_ep}\")\nplt.xlabel(\"Domain\"); plt.ylabel(\"SSIM\")\nplt.xticks(rotation=20); plt.grid(True, axis=\"y\"); plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==== Present results: tables and quick summaries ====\nimport os\nimport pandas as pd\nimport numpy as np\n\nMETRICS_CSV = \"/kaggle/working/sample_metrics.csv\"\nassert os.path.exists(METRICS_CSV), \"sample_metrics.csv not found.\"\n\ndf = pd.read_csv(METRICS_CSV)  # epoch,domain,name,psnr,ssim\ndf[\"epoch\"] = df[\"epoch\"].astype(int)\n\n# Mean/std per (epoch, domain)\nagg = df.groupby([\"epoch\",\"domain\"], as_index=False).agg(\n    psnr_mean=(\"psnr\",\"mean\"),\n    psnr_std =(\"psnr\",\"std\"),\n    ssim_mean=(\"ssim\",\"mean\"),\n    ssim_std =(\"ssim\",\"std\"),\n    n=(\"name\",\"count\")\n).sort_values([\"domain\",\"epoch\"])\n\n# 1) Best epoch per domain (by PSNR and by SSIM)\nidx_psnr = agg.groupby(\"domain\")[\"psnr_mean\"].idxmax()\nidx_ssim = agg.groupby(\"domain\")[\"ssim_mean\"].idxmax()\nbest_psnr = agg.loc[idx_psnr].reset_index(drop=True)\nbest_ssim = agg.loc[idx_ssim].reset_index(drop=True)\n\nprint(\"=== Best Epoch per Domain (by PSNR) ===\")\ndisplay(best_psnr[[\"domain\",\"epoch\",\"psnr_mean\",\"psnr_std\",\"n\"]])\n\nprint(\"=== Best Epoch per Domain (by SSIM) ===\")\ndisplay(best_ssim[[\"domain\",\"epoch\",\"ssim_mean\",\"ssim_std\",\"n\"]])\n\n# 2) Last epoch summary (mean ± std) per domain\nlast_ep = agg[\"epoch\"].max()\nlast = agg[agg[\"epoch\"] == last_ep].copy().sort_values(\"domain\")\n\n# readable columns for a report\nlast[\"PSNR (mean±std)\"] = last[\"psnr_mean\"].round(3).astype(str) + \" ± \" + last[\"psnr_std\"].fillna(0).round(3).astype(str)\nlast[\"SSIM (mean±std)\"] = last[\"ssim_mean\"].round(4).astype(str) + \" ± \" + last[\"ssim_std\"].fillna(0).round(4).astype(str)\n\nprint(f\"=== Last Epoch Summary (Epoch {last_ep}) ===\")\ndisplay(last[[\"domain\",\"PSNR (mean±std)\",\"SSIM (mean±std)\",\"n\"]])\n\n# 3) Save tidy CSVs for report attachments\nOUT_DIR = \"/kaggle/working\"\nagg.to_csv(os.path.join(OUT_DIR, \"sample_metrics_aggregated.csv\"), index=False)\nbest_psnr.to_csv(os.path.join(OUT_DIR, \"best_epochs_by_psnr.csv\"), index=False)\nbest_ssim.to_csv(os.path.join(OUT_DIR, \"best_epochs_by_ssim.csv\"), index=False)\n\nprint(\"\\nSaved:\")\nprint(\" - /kaggle/working/sample_metrics_aggregated.csv\")\nprint(\" - /kaggle/working/best_epochs_by_psnr.csv\")\nprint(\" - /kaggle/working/best_epochs_by_ssim.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}